{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a779dd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# quick ETL demo analytics\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "conn = sqlite3.connect('data/epic_synth.db')\n",
    "# counts\n",
    "counts = {t: conn.execute(f\"select count(*) from {t}\").fetchone()[0] for t in ['person','observation','condition','visit_occurrence','measurement','variant_pathogenic','variant_vrs'] if True}\n",
    "print(counts)\n",
    "# top genes by pathogenic variant count\n",
    "q = \"select GeneSymbol, count(*) as c from variant_pathogenic group by GeneSymbol order by c desc limit 10\"\n",
    "top_genes = pd.read_sql(q, conn)\n",
    "print('\\nTop genes by pathogenic variants:')\n",
    "print(top_genes)\n",
    "\n",
    "# tiny ML demo skeleton: build a table of gene-level features (pathogenic variant counts) and a dummy target\n",
    "vg = pd.read_sql('select GeneSymbol, count(*) as pathogenic_count from variant_pathogenic group by GeneSymbol', conn)\n",
    "# simple target: genes with > 50 pathogenic variants flagged as 1\n",
    "vg['target'] = (vg['pathogenic_count'] > 50).astype(int)\n",
    "print('\\nML sample head:')\n",
    "print(vg.head())\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e6f2cea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variant index and patient-join demo\n",
    "# Create a compact variant_index table from variant_vrs and a small synthetic patient_variant mapping for demo joins.\n",
    "import sqlite3\n",
    "conn = sqlite3.connect('data/epic_synth.db')\n",
    "cur = conn.cursor()\n",
    "# create variant_index: distinct vrs_id, gene, clinical_count\n",
    "cur.execute('''\n",
    "CREATE TABLE IF NOT EXISTS variant_index AS\n",
    "SELECT vrs_id, GeneSymbol, count(*) as n_occurrences\n",
    "FROM variant_vrs\n",
    "GROUP BY vrs_id, GeneSymbol\n",
    "''')\n",
    "conn.commit()\n",
    "# create a tiny patient_variant mapping for demo: sample first 100 vrs_ids and assign randomly to patients\n",
    "cur.execute('CREATE TABLE IF NOT EXISTS patient_variant (person_id INTEGER, vrs_id TEXT)')\n",
    "cur.execute('DELETE FROM patient_variant')\n",
    "# pick up to 100 vrs_ids\n",
    "v = cur.execute('select vrs_id from variant_vrs limit 100').fetchall()\n",
    "import random\n",
    "persons = [r[0] for r in cur.execute('select rowid from person').fetchall()]\n",
    "for i, (vrs,) in enumerate(v):\n",
    "    pid = persons[i % len(persons)]\n",
    "    cur.execute('insert into patient_variant (person_id,vrs_id) values (?,?)', (pid, vrs))\n",
    "conn.commit()\n",
    "# example join: list persons with pathogenic variant counts via variant_index\n",
    "q = '''\n",
    "select p.rowid as person_id, p.* , vi.n_occurrences\n",
    "from person p\n",
    "join patient_variant pv on pv.person_id = p.rowid\n",
    "join variant_index vi on vi.vrs_id = pv.vrs_id\n",
    "limit 20\n",
    "'''\n",
    "import pandas as pd\n",
    "print(pd.read_sql(q, conn))\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08885dc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ML train/validate demo\n",
    "# This cell prepares training data from the gene-level table and runs a small sklearn pipeline.\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report, roc_auc_score\n",
    "\n",
    "# load gene-level features created earlier\n",
    "conn = sqlite3.connect('data/epic_synth.db')\n",
    "vg = pd.read_sql('select GeneSymbol, pathogenic_count as pathogenic_count from (select GeneSymbol, count(*) as pathogenic_count from variant_pathogenic group by GeneSymbol)', conn)\n",
    "# create numeric feature\n",
    "X = vg[['pathogenic_count']].fillna(0)\n",
    "y = (vg['pathogenic_count'] > 50).astype(int)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "pipe = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('clf', LogisticRegression(max_iter=1000))\n",
    "])\n",
    "pipe.fit(X_train, y_train)\n",
    "y_pred = pipe.predict(X_test)\n",
    "y_proba = pipe.predict_proba(X_test)[:,1]\n",
    "print(classification_report(y_test, y_pred))\n",
    "try:\n",
    "    print('ROC AUC:', roc_auc_score(y_test, y_proba))\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "# save model to disk\n",
    "import joblib\n",
    "joblib.dump(pipe, 'data/gene_level_model.joblib')\n",
    "print('model saved to data/gene_level_model.joblib')\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b96cb7f",
   "metadata": {},
   "source": [
    "# ETL Demo\n",
    "Run the ETL to load FHIR JSON into SQLite and preview tables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "13199609",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'epic_etl'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Example: run the ETL process on data/fhir -> data/epic_synth.db\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mepic_etl\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m run_etl\n\u001b[1;32m      3\u001b[0m run_etl\u001b[38;5;241m.\u001b[39mprocess_fhir_dir(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata/fhir\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata/epic_synth.db\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mETL completed\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'epic_etl'"
     ]
    }
   ],
   "source": [
    "# Example: run the ETL process on data/fhir -> data/epic_synth.db\n",
    "from epic_etl import run_etl\n",
    "run_etl.process_fhir_dir('data/fhir', 'data/epic_synth.db')\n",
    "print('ETL completed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "539e2bc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3, pandas as pd\n",
    "conn = sqlite3.connect('data/epic_synth.db')\n",
    "print(pd.read_sql('SELECT * FROM person LIMIT 5', conn))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AIBackEnd",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
