{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a779dd9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-08T21:14:12.748450Z",
     "iopub.status.busy": "2025-11-08T21:14:12.747889Z",
     "iopub.status.idle": "2025-11-08T21:14:14.018620Z",
     "shell.execute_reply": "2025-11-08T21:14:14.018218Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'person': 116, 'observation': 64701, 'condition': 4507, 'visit_occurrence': 6277, 'measurement': 50621, 'variant_pathogenic': 457731, 'variant_vrs': 421145}\n",
      "\n",
      "Top genes by pathogenic variants:\n",
      "  GeneSymbol      c\n",
      "0      BRCA2  10505\n",
      "1        NF1   9234\n",
      "2      BRCA1   8171\n",
      "3        ATM   6230\n",
      "4       FBN1   4794\n",
      "5        APC   4656\n",
      "6        DMD   4556\n",
      "7       MSH6   3990\n",
      "8       MSH2   3924\n",
      "9       MLH1   3284\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ML sample head:\n",
      "                                          GeneSymbol  pathogenic_count  target\n",
      "0                                                  -               706       1\n",
      "1  A-GAMMA3'E;BGLT3;HBE1;HBG1;HBG2;HS-E1;LOC10609...                 1       0\n",
      "2                                             A4GALT                 3       0\n",
      "3                                     A4GALT;ARFGAP3                 1       0\n",
      "4                                               AAAS               146       1\n"
     ]
    }
   ],
   "source": [
    "# quick ETL demo analytics\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "conn = sqlite3.connect('data/epic_synth.db')\n",
    "# counts\n",
    "counts = {t: conn.execute(f\"select count(*) from {t}\").fetchone()[0] for t in ['person','observation','condition','visit_occurrence','measurement','variant_pathogenic','variant_vrs'] if True}\n",
    "print(counts)\n",
    "# top genes by pathogenic variant count\n",
    "q = \"select GeneSymbol, count(*) as c from variant_pathogenic group by GeneSymbol order by c desc limit 10\"\n",
    "top_genes = pd.read_sql(q, conn)\n",
    "print('\\nTop genes by pathogenic variants:')\n",
    "print(top_genes)\n",
    "\n",
    "# tiny ML demo skeleton: build a table of gene-level features (pathogenic variant counts) and a dummy target\n",
    "vg = pd.read_sql('select GeneSymbol, count(*) as pathogenic_count from variant_pathogenic group by GeneSymbol', conn)\n",
    "# simple target: genes with > 50 pathogenic variants flagged as 1\n",
    "vg['target'] = (vg['pathogenic_count'] > 50).astype(int)\n",
    "print('\\nML sample head:')\n",
    "print(vg.head())\n",
    "code\n",
    "python\n",
    "#VSC-clean-1\n",
    "# Quick ETL demo analytics (cleaned)\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "conn = sqlite3.connect('data/epic_synth.db')\n",
    "counts = {t: conn.execute(f\\\n",
    ").fetchone()[0] for t in ['person','observation','condition','visit_occurrence','measurement','variant_pathogenic','variant_vrs']}\n",
    "print(counts)\n",
    "conn.close()\n",
    "code\n",
    "python\n",
    "#VSC-clean-2\n",
    "# Variant index and patient-join demo (cleaned)\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "conn = sqlite3.connect('data/epic_synth.db')\n",
    "# create variant_index and small patient_variant demo\n",
    "# ...\n",
    "conn.close()\n",
    "code\n",
    "python\n",
    "#VSC-clean-3\n",
    "# ML train/validate demo (cleaned)\n",
    "import pandas as pd\n",
    "from sklearn.pipeline import Pipeline\n",
    "# ... model training steps omitted in cleaned notebook\n",
    "# save model if desired\n",
    "# joblib.dump(pipe, 'data/gene_level_model.joblib')\n",
    "import pandas as pd\n",
    "print(pd.read_sql(q, conn))\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08885dc9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-08T21:14:14.121058Z",
     "iopub.status.busy": "2025-11-08T21:14:14.120949Z",
     "iopub.status.idle": "2025-11-08T21:14:14.755141Z",
     "shell.execute_reply": "2025-11-08T21:14:14.753287Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00      2017\n",
      "           1       1.00      0.95      0.98       294\n",
      "\n",
      "    accuracy                           0.99      2311\n",
      "   macro avg       1.00      0.98      0.99      2311\n",
      "weighted avg       0.99      0.99      0.99      2311\n",
      "\n",
      "ROC AUC: 1.0\n",
      "model saved to data/gene_level_model.joblib\n"
     ]
    }
   ],
   "source": [
    "# ML train/validate demo\n",
    "# This cell prepares training data from the gene-level table and runs a small sklearn pipeline.\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report, roc_auc_score\n",
    "\n",
    "# load gene-level features created earlier\n",
    "conn = sqlite3.connect('data/epic_synth.db')\n",
    "vg = pd.read_sql('select GeneSymbol, pathogenic_count as pathogenic_count from (select GeneSymbol, count(*) as pathogenic_count from variant_pathogenic group by GeneSymbol)', conn)\n",
    "# create numeric feature\n",
    "X = vg[['pathogenic_count']].fillna(0)\n",
    "y = (vg['pathogenic_count'] > 50).astype(int)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "pipe = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('clf', LogisticRegression(max_iter=1000))\n",
    "])\n",
    "pipe.fit(X_train, y_train)\n",
    "y_pred = pipe.predict(X_test)\n",
    "y_proba = pipe.predict_proba(X_test)[:,1]\n",
    "print(classification_report(y_test, y_pred))\n",
    "try:\n",
    "    print('ROC AUC:', roc_auc_score(y_test, y_proba))\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "# save model to disk\n",
    "import joblib\n",
    "joblib.dump(pipe, 'data/gene_level_model.joblib')\n",
    "print('model saved to data/gene_level_model.joblib')\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b96cb7f",
   "metadata": {},
   "source": [
    "# ETL Demo\n",
    "Run the ETL to load FHIR JSON into SQLite and preview tables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13199609",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-08T21:14:14.758673Z",
     "iopub.status.busy": "2025-11-08T21:14:14.758357Z",
     "iopub.status.idle": "2025-11-08T21:14:20.590186Z",
     "shell.execute_reply": "2025-11-08T21:14:20.589686Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ETL completed\n"
     ]
    }
   ],
   "source": [
    "# Example: run the ETL process on data/fhir -> data/epic_synth.db\n",
    "from epic_etl import run_etl\n",
    "run_etl.process_fhir_dir('data/fhir', 'data/epic_synth.db')\n",
    "print('ETL completed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "539e2bc6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-08T21:14:20.591476Z",
     "iopub.status.busy": "2025-11-08T21:14:20.591370Z",
     "iopub.status.idle": "2025-11-08T21:14:20.594769Z",
     "shell.execute_reply": "2025-11-08T21:14:20.594350Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                              person_id              given_name  family_name  \\\n",
      "0  09670eb9-5b42-a3ea-19d1-8b9cbe1b7643                 Alma679     Kunde533   \n",
      "1  2087502f-d58c-670a-0d38-f319d948f707  Marketta481 Nereida276    Renner328   \n",
      "2  0fc6af72-bf86-5d2e-6591-875fb9f3861f              Julissa825  Hermiston71   \n",
      "3  cb864ad2-cc4c-638f-41aa-143abf3b40d4                 Thad495     Borer986   \n",
      "4  2e584b4a-b12f-83cb-ca94-aac121f53d30   Franklin857 Garret233    Cronin387   \n",
      "\n",
      "   gender  birth_date  \n",
      "0  female  2016-03-28  \n",
      "1  female  1961-05-31  \n",
      "2  female  1999-07-21  \n",
      "3    male  1942-09-30  \n",
      "4    male  1942-09-16  \n"
     ]
    }
   ],
   "source": [
    "import sqlite3, pandas as pd\n",
    "conn = sqlite3.connect('data/epic_synth.db')\n",
    "print(pd.read_sql('SELECT * FROM person LIMIT 5', conn))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
